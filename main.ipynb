{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:12:20.715963Z",
     "start_time": "2022-06-05T08:12:18.868653Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os.path as op\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "from model.net import Net\n",
    "from utils import NetworkData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:12:23.010653Z",
     "start_time": "2022-06-05T08:12:22.999097Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "weight_decay = 5e-4\n",
    "num_epochs = 10\n",
    "# val_ratio = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:25:07.136357Z",
     "start_time": "2022-06-05T08:12:26.279965Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34404 419840\n",
      "building adjacency ...\n",
      "normalize adjacency ...\n",
      "building node features ...\n",
      "building node features ...\n",
      "building edge features ...\n",
      "building edge features ...\n",
      "get data: \tnumber of users: 34404\n",
      "number of songs: 419840\n",
      "adjacency: (454244, 454244)\n",
      "Lap: (454244, 454244)\n",
      "dim of user feature: 6\n"
     ]
    }
   ],
   "source": [
    "data = NetworkData(cache=None, save=False)\n",
    "adj, L, x_user, x_item, x_train_edge, x_test_edge, y_train = data.get_data()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:30:08.193828Z",
     "start_time": "2022-06-05T08:30:08.157292Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xh/jth0z5cd3gvbvnjcg95dy6nc0000gn/T/ipykernel_94585/1708691962.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  x_user = x_user / x_user.sum(1, keepdims=True)\n",
      "/var/folders/xh/jth0z5cd3gvbvnjcg95dy6nc0000gn/T/ipykernel_94585/1708691962.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x_user = x_user / x_user.sum(1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "# norm\n",
    "x_user = x_user / x_user.sum(1, keepdims=True)\n",
    "x_item = x_item / x_item.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:30:15.545681Z",
     "start_time": "2022-06-05T08:30:15.500009Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# to tensor\n",
    "x_user = torch.from_numpy(np.float32(x_user))\n",
    "x_item = torch.from_numpy(np.float32(x_item))\n",
    "y_train = torch.from_numpy(np.array(y_train))\n",
    "\n",
    "num_user_nodes, user_input_dim = x_user.shape\n",
    "num_item_nodes, item_input_dim = x_item.shape\n",
    "hidden_dim = 500\n",
    "embedding_dim = 500\n",
    "edge_dim = len(x_train_edge['9176-86884'])\n",
    "num_nodes = num_item_nodes + num_user_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:30:19.505786Z",
     "start_time": "2022-06-05T08:30:19.399474Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "indices = torch.from_numpy(np.array([L.row, L.col]).astype(\"int64\")).long()\n",
    "values = torch.from_numpy(L.data.astype(np.float32))\n",
    "adjacency = torch.sparse.FloatTensor(indices, values, L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:30:23.989392Z",
     "start_time": "2022-06-05T08:30:23.970900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([454244, 454244])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:30:27.115451Z",
     "start_time": "2022-06-05T08:30:27.073041Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Net(user_input_dim, item_input_dim, hidden_dim, embedding_dim, edge_dim, use_edge_feature=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:30:31.265085Z",
     "start_time": "2022-06-05T08:30:31.253811Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train\n",
    "def train():\n",
    "    loss_history = []\n",
    "    acc_history = []\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        logits = model(adjacency, x_user, x_item, x_train_edge)\n",
    "        loss = criterion(logits, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "        acc = accuracy(logits, y_train)\n",
    "        acc_history.append(acc.item())\n",
    "        print(\"Epoch {:03d}: Loss {:.4f}, TrainAcc {:.4f}\".format(\n",
    "            epoch, loss.item(), acc.item()\n",
    "        ))\n",
    "    return loss_history, acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:30:32.963446Z",
     "start_time": "2022-06-05T08:30:31.945506Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "def accuracy(logits, y):\n",
    "    ones = torch.ones_like(logits)\n",
    "    zeros = torch.zeros_like(logits)\n",
    "    y_hat = torch.where(logits > 0.5, ones, logits)\n",
    "    y_hat = torch.where(logits <= 0.5, zeros, logits)\n",
    "    return (y_hat == y).sum() / len(y_hat)\n",
    "\n",
    "# plot\n",
    "from matplotlib import pyplot as plt\n",
    "def plot_loss_and_acc(loss_history, acc_history):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.plot(range(len(loss_history)), loss_history,\n",
    "             c=np.array([255, 71, 90]) / 255.)\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    ax2 = fig.add_subplot(111, sharex=ax1, frameon=False)\n",
    "    ax2.plot(range(len(acc_history)), acc_history,\n",
    "             c=np.array([79, 179, 255]) / 255.)\n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    plt.ylabel('TrainAcc')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title('Training Loss & Training Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T08:30:35.057069Z",
     "start_time": "2022-06-05T08:30:33.076047Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duran/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "addmm: Argument #3 (dense): Expected dim 0 size 454244, got 450416",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loss, acc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m plot_loss_and_acc(loss, acc)\n",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m----> 8\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43madjacency\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_user\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_item\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_train_edge\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(logits, y_train)\n\u001B[1;32m     11\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/kkbox-music-recommendation/model/net.py:30\u001B[0m, in \u001B[0;36mNet.forward\u001B[0;34m(self, adjacency, user_feat, item_feat, edge_feature)\u001B[0m\n\u001B[1;32m     26\u001B[0m item_proj_feat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproj_item(item_feat))\n\u001B[1;32m     28\u001B[0m feat \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((user_proj_feat, item_proj_feat), \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 30\u001B[0m embd_user \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgnn_user\u001B[49m\u001B[43m(\u001B[49m\u001B[43madjacency\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeat\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m embd_item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgnn_item(adjacency, feat)\n\u001B[1;32m     33\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmul(embd_user, embd_item)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/kkbox-music-recommendation/model/gnn.py:39\u001B[0m, in \u001B[0;36mGNN.forward\u001B[0;34m(self, adjacency, features)\u001B[0m\n\u001B[1;32m     37\u001B[0m x \u001B[38;5;241m=\u001B[39m features\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# GCN layer\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m gcn1_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgcn1\u001B[49m\u001B[43m(\u001B[49m\u001B[43madjacency\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(gcn1_x)\n\u001B[1;32m     41\u001B[0m gcn2_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgcn2(adjacency, x)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/kkbox-music-recommendation/model/gnn.py:65\u001B[0m, in \u001B[0;36mGCNLayer.forward\u001B[0;34m(self, adjacency, features)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, adjacency, features):\n\u001B[1;32m     64\u001B[0m     h \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmm(features, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight)\n\u001B[0;32m---> 65\u001B[0m     h \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43madjacency\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_bias:\n\u001B[1;32m     67\u001B[0m         h \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mclone() \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/sparse/__init__.py:91\u001B[0m, in \u001B[0;36mmm\u001B[0;34m(mat1, mat2)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mat1\u001B[38;5;241m.\u001B[39mis_sparse \u001B[38;5;129;01mand\u001B[39;00m mat2\u001B[38;5;241m.\u001B[39mis_sparse:\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_sparse_sparse_matmul(mat1, mat2)\n\u001B[0;32m---> 91\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sparse_mm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmat1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmat2\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: addmm: Argument #3 (dense): Expected dim 0 size 454244, got 450416"
     ]
    }
   ],
   "source": [
    "loss, acc = train()\n",
    "plot_loss_and_acc(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450416"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}